p8105_hw2_fl2715
================
Fengwei Lei

## Load Necessary Library

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

``` r
nyc_df=
  read_csv(
    "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The above dataset contains information from
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. It includes variables
such as subway line, station name, latitude, longitude, routes served,
entry status, exit-only status, vending availability, entrance type, and
ADA compliance. Data cleaning steps involved handling missing values,
cleaning column names, selecting relevant variables, and converting the
entry variable from “YES”/“NO” to a logical format (TRUE/FALSE). The
resulting dataset has 1868 rows and 20 columns.

But these data is not fully “tidy”: both the route number and route
should be treated as variables. To make the dataset tidy, we need to
reshape the route variables from wide to long format. This restructuring
is helpful when analyzing specific routes.

The below code shows that the number of distinct stations identified
both by name and line, where we use the `distinct()` fuction.

``` r
nyc_df |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

The following code chunk illustrates the number of stations which are
ADA compliant. Firstly, we filter the rows where `ada == TRUE`. And we
do the similar steps to the above code chunk.

``` r
nyc_df |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

The following code chunk shows the proportion of station entrances /
exits without vending allow entrance. We firstly filter the rows where
there is no vending. And since the variable `entry` is a logical
variable, we could compute the mean for calculating proportion.

``` r
nyc_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

    ## [1] 0.3770492

Finally, we compute the number of distinct stations that serve the A
train, and that are ADA compliant. To reformat the data successfully, we
firstly convert the variables `route8`, `route9`, `route10` and
`route11` into character type, since they were double type before. After
that, we tidy the data with converting `route` from wide to long format.
And then, we use `filter()`, `select()`, `distinct()` function to find
the regarding results (similar to the above steps).

``` r
nyc_df=
  nyc_df |> 
  mutate(
    route8=as.character(route8),
    route9=as.character(route9),
    route10=as.character(route10),
    route11=as.character(route11))

nyc_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

``` r
nyc_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

From the above reformat data, we can see that there are **60** distinct
stations serve the A train. And **17** Of the stations that serve the A
train and are ADA compliant.

## Problem 2

### Read and Clean Mr. Trash Wheel Data

The following code block reads the Mr. Trash Wheel sheet from the Excel
file, starting from the second row to skip the header. We use
`janitor::clean_names()` to clean the column names. Then, we apply
`filter()` to remove rows with missing values in the dumpster column,
retaining only those that contain specific dumpster data. Next, we use
`mutate()` to round the values in the sports_balls column to the nearest
integer and convert them to integer type while adding a source column to
indicate that the data comes from “Mr.”

``` r
mr_trash_wheel=
  read_excel(
    "./202409 Trash Wheel Collection Data.xlsx",
    sheet="Mr. Trash Wheel",
    range="A2:N655") |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    source="Mr"
  )

mr_trash_wheel
```

    ## # A tibble: 651 × 15
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 641 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, source <chr>

### Read and Clean Professor Trash Wheel Data

Next code chunk reads the Professor Trash Wheel sheet from the Excel
file, also starting from the second row. Apart form the similar steps in
above manipulation, in the `mutate()` function, a new column
sports_balls is created and set to 0, as this data source does not have
corresponding sports ball data. Additionally, the year column is
converted to character type to maintain consistency with Mr. Trash Wheel
dataset, and a source column is added to indicate that the data comes
from “Professor.”

``` r
pro_trash_wheel=
  read_excel(
    "./202409 Trash Wheel Collection Data.xlsx",
    sheet="Professor Trash Wheel",
    range="A2:M123") |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = 0,
    year = as.character(year),
    source="Professor"
  )

pro_trash_wheel
```

    ## # A tibble: 119 × 15
    ##    dumpster month    year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 January  2017  2017-01-02 00:00:00        1.79                 15
    ##  2        2 January  2017  2017-01-30 00:00:00        1.58                 15
    ##  3        3 February 2017  2017-02-26 00:00:00        2.32                 18
    ##  4        4 February 2017  2017-02-26 00:00:00        3.72                 15
    ##  5        5 February 2017  2017-02-28 00:00:00        1.45                 15
    ##  6        6 March    2017  2017-03-30 00:00:00        1.71                 15
    ##  7        7 April    2017  2017-04-01 00:00:00        1.82                 15
    ##  8        8 April    2017  2017-04-20 00:00:00        2.37                 15
    ##  9        9 May      2017  2017-05-10 00:00:00        2.64                 15
    ## 10       10 May      2017  2017-05-26 00:00:00        2.78                 15
    ## # ℹ 109 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, sports_balls <dbl>, source <chr>

### Read and Clean Gwynnda Trash Wheel Data

Similar steps are applied to Gwynnda Trash Wheel Data for the Gwynnda
Trash Wheel sheet from the Excel file.

``` r
gwy_trash_wheel=
  read_excel(
    "./202409 Trash Wheel Collection Data.xlsx",
    sheet="Gwynnda Trash Wheel",
    range="A2:L266") |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = 0,
    year = as.character(year),
    source="Gwynnda"
  )

gwy_trash_wheel
```

    ## # A tibble: 263 × 14
    ##    dumpster month  year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 July   2021  2021-07-03 00:00:00        0.93                 15
    ##  2        2 July   2021  2021-07-07 00:00:00        2.26                 15
    ##  3        3 July   2021  2021-07-07 00:00:00        1.62                 15
    ##  4        4 July   2021  2021-07-16 00:00:00        1.76                 15
    ##  5        5 July   2021  2021-07-30 00:00:00        1.53                 15
    ##  6        6 August 2021  2021-08-11 00:00:00        2.06                 15
    ##  7        7 August 2021  2021-08-14 00:00:00        1.9                  15
    ##  8        8 August 2021  2021-08-16 00:00:00        2.16                 15
    ##  9        9 August 2021  2021-08-16 00:00:00        2.6                  15
    ## 10       10 August 2021  2021-08-17 00:00:00        3.21                 15
    ## # ℹ 253 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, sports_balls <dbl>, source <chr>

### Combine All Cleaned Datasets

Finally, we use the bind_rows() function to combine the three cleaned
datasets (mr_trash_wheel, pro_trash_wheel, and gwy_trash_wheel) into a
single tidy dataset called trash_tidy. This operation concatenates the
rows from each dataset in order, forming a comprehensive table that
contains all Trash Wheel data, making it easier for subsequent analysis
and processing.

``` r
trash_tidy=
  bind_rows(mr_trash_wheel, pro_trash_wheel, gwy_trash_wheel)

trash_tidy
```

    ## # A tibble: 1,033 × 15
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,023 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, source <chr>

The combined dataset contains a total of 1033 observations, representing
data collected from three different Trash Wheels: Mr. Trash Wheel,
Professor Trash Wheel, and Gwynnda. Key variables in this dataset
include date, dumpsters, weight_tons, sports_balls, and source, which
provide insights into the amount and type of trash collected. From the
available data, the total weight of trash collected by Professor Trash
Wheel is **246.74** tons. Additionally, during June 2022, Gwynnda
collected a total of **18120** cigarette butts, illustrating the impact
of trash collection efforts in the community.

## Problem 3

### Import Datasets

``` r
bakers_df=
  readr::read_csv(
    "./gbb_datasets/bakers.csv",
    na = c("NA", ".", "")) |>
  janitor::clean_names() |> 
  separate(baker_name, into = c("baker", "baker_last_name"), sep = " ", extra = "merge", fill = "right")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df=
  readr::read_csv(
    "./gbb_datasets/bakes.csv",
    na = c("NA", ".", "")) |>
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df=
  readr::read_csv(
    "./gbb_datasets/results.csv",
    na = c("NA", ".", ""),
    skip = 2) |>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Data Cleaning Process

First, we inspect the data for completeness and correctness by viewing
these three individual datasets and checking for missing or inconsistent
data. We use `anti_join()` to examine whether there exist any
mismatching between the datasets.

- Compare `results_df` and `bakes_df`

``` r
diff_results_bakes=anti_join(results_df, bakes_df, by=c("series", "episode", "baker"))
diff_results_bakes
```

    ## # A tibble: 596 × 5
    ##    series episode baker    technical result
    ##     <dbl>   <dbl> <chr>        <dbl> <chr> 
    ##  1      1       2 Lea             NA <NA>  
    ##  2      1       2 Mark            NA <NA>  
    ##  3      1       3 Annetha         NA <NA>  
    ##  4      1       3 Lea             NA <NA>  
    ##  5      1       3 Louise          NA <NA>  
    ##  6      1       3 Mark            NA <NA>  
    ##  7      1       4 Annetha         NA <NA>  
    ##  8      1       4 Jonathan        NA <NA>  
    ##  9      1       4 Lea             NA <NA>  
    ## 10      1       4 Louise          NA <NA>  
    ## # ℹ 586 more rows

From the above results, we find that there are 596 rows, which means
that 596 rows in `results_df` but not in `bakes_df` according to
variables “series”,“episode”, “baker”. But the difference of the rows
between `results_df` and `bakes_df` is 1136 - 548= 588, which is not
equal to 596. That means there are some tricky rows in `bakes_df` but
not in `results_df` for the variables combination of “series”,“episode”,
and “baker”.

- Compare `bakes_df` and `bakers_df`

``` r
diff_bakes_bakers=anti_join(bakes_df, bakers_df, by = "baker")
diff_bakes_bakers
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

Interestingly, for the difference of the variable `baker` between
`bakes_df` and `bakers_df`, we find there are some stranger names
**“Jo”** in `bakes_df`. That might be a wrong recording information. So
we need to convert **“Jo”** into **Jo**.

- Compare `results_df` and `bakers_df`

``` r
diff_results_bakers=anti_join(results_df, bakers_df, by = "baker")
diff_results_bakers
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

The above results shows that there is one baker named “Joanne”, who
exits in `results_df` but not in `bakers_df`. Besides, we examine that
Joanne does not exist in `bakes_df` neither. ***It is a reasonable
explanation that **Joanne** and **Jo** is exactly the same person!***

So we now clean the bakers’ names in `bakes_df` and `results_df`! We
convert **“Jo”** into **Jo** in `bakes_df` and **Joanne** into **Jo** in
`results_df` for consistency.

``` r
bakes_df = bakes_df |>
  mutate( baker = str_replace(baker, "\"Jo\"", "Jo"))

results_df= results_df |> 
  mutate(baker=str_replace(baker, "Joanne", "Jo"))
```

Now we check the differences and consistency of these three data sets
after modifying the name.

``` r
diff_results_bakes=anti_join(results_df, bakes_df, by=c("series", "episode", "baker"))
diff_results_bakes
```

    ## # A tibble: 588 × 5
    ##    series episode baker    technical result
    ##     <dbl>   <dbl> <chr>        <dbl> <chr> 
    ##  1      1       2 Lea             NA <NA>  
    ##  2      1       2 Mark            NA <NA>  
    ##  3      1       3 Annetha         NA <NA>  
    ##  4      1       3 Lea             NA <NA>  
    ##  5      1       3 Louise          NA <NA>  
    ##  6      1       3 Mark            NA <NA>  
    ##  7      1       4 Annetha         NA <NA>  
    ##  8      1       4 Jonathan        NA <NA>  
    ##  9      1       4 Lea             NA <NA>  
    ## 10      1       4 Louise          NA <NA>  
    ## # ℹ 578 more rows

``` r
diff_bakes_bakers=anti_join(bakes_df, bakers_df, by = "baker")
diff_bakes_bakers
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
diff_results_bakers=anti_join(results_df, bakers_df, by = "baker")
diff_results_bakers
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

Now the results are the same as we expected. So we complete checking for
completeness and correctness across datasets and move to merging step.
